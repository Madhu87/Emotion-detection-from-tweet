{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import inflect\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string, unicodedata\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweet_emotions.csv', delimiter=',')\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Number of classes from 13 to 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reducing Classes to 3: \n",
      " sadness      23874\n",
      "happiness    16126\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat = []\n",
    "def class_change(df):\n",
    "    for x in df.sentiment:\n",
    "        if x in ['happiness', 'relief', 'love', 'surprise', 'fun', 'enthusiasm','empty']:\n",
    "            cat.append('happiness')\n",
    "        else :\n",
    "            cat.append('sadness')\n",
    "            \n",
    "class_change(df)\n",
    "df['sentiment'] = cat\n",
    "print('After Reducing Classes to 3: \\n',df.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------- User defined function for preprocessing \"content\" column --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(df, text_col, remove_stopwords=True):\n",
    "    \n",
    "    # -----------------------------------------Function to denoise text------------------------------------------\n",
    "    def denoise_text(text):\n",
    "        # Strip html if any. For ex. removing <html>, <p> tags\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "        # Contractions replacement in the text. (For ex. didn't -> did not)\n",
    "        text = contractions.fix(text)\n",
    "        return text\n",
    "    \n",
    "    #---------------------------------------------Text Normalization --------------------------------------------    \n",
    "    \n",
    "    def remove_non_ascii(words):\n",
    "        \"\"\"Remove non-ASCII characters\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def to_lowercase(words):\n",
    "        \"\"\"Convert all characters to lowercase\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = word.lower()\n",
    "            new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def remove_punctuation(words):\n",
    "        \"\"\"Remove punctuation\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def replace_numbers(words):\n",
    "        \"\"\"Replace all interger occurrences with textual representation\"\"\"\n",
    "        p = inflect.engine()\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word.isdigit():\n",
    "                new_word = p.number_to_words(word)\n",
    "                new_words.append(new_word)\n",
    "            else:\n",
    "                new_words.append(word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def remove_stopwords(words):\n",
    "        \"\"\"Remove stop words\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word not in stopwords.words('english'):\n",
    "                new_words.append(word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def stem_words(words):\n",
    "        \"\"\"Stem words\"\"\"\n",
    "        stemmer = LancasterStemmer()\n",
    "        stems = []\n",
    "        for word in words:\n",
    "            stem = stemmer.stem(word)\n",
    "            stems.append(stem)\n",
    "        return stems\n",
    "    \n",
    "    \n",
    "    def lemmatize_verbs(words):\n",
    "        \"\"\"Lemmatize verbs\"\"\"\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmas = []\n",
    "        for word in words:\n",
    "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "            lemmas.append(lemma)\n",
    "        return lemmas\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------A wrap-up function for normalization------------------------------\n",
    "    def normalize_text(words, remove_stopwords):\n",
    "        words = remove_non_ascii(words)\n",
    "        words = to_lowercase(words)\n",
    "        words = remove_punctuation(words)\n",
    "        words = replace_numbers(words)\n",
    "        if remove_stopwords:\n",
    "            words = remove_stopwords(words)\n",
    "        #words = stem_words(words)\n",
    "        words = lemmatize_verbs(words)\n",
    "        return words\n",
    "    \n",
    "    # All above functions work on word tokens we need a tokenizer\n",
    "    \n",
    "    #-------------------------------------- Tokenize tweet into words ----------------------------\n",
    "    def tokenize(text):\n",
    "        return nltk.word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    # A overall wrap-up function\n",
    "    def text_prepare(text):\n",
    "        text = denoise_text(text)\n",
    "        text = ' '.join([x for x in normalize_text(tokenize(text), remove_stopwords)])\n",
    "        return text\n",
    "    \n",
    "    # run every-step\n",
    "    df[text_col] = [text_prepare(x) for x in df[text_col]]\n",
    "    \n",
    "    \n",
    "    # --------------------------------------return processed df----------------------------------\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of data before and after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Text Preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2                Funeral ceremony...gloomy friday...\n",
       "3               wants to hang out with friends SOON!\n",
       "4  @dannycastillo We want to trade with someone w..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Text Preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layin n bed headache ughhhh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want hang friends soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dannycastillo want trade someone houston ticke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  tiffanylue know listenin bad habit earlier sta...\n",
       "1            layin n bed headache ughhhh waitin call\n",
       "2                     funeral ceremony gloomy friday\n",
       "3                             want hang friends soon\n",
       "4  dannycastillo want trade someone houston ticke..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Before Text Preprocessing\")\n",
    "display(df.head()[['content']])\n",
    "processed_df = text_preprocessing(df, 'content', remove_stopwords=False)\n",
    "print(\"After Text Preprocessing\")\n",
    "display(processed_df.head()[['content']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction - Removing 'tweet_id' column and dropping Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data before Preprocessing :  (40000, 3)\n",
      "Shape of data after Preprocessing and dimensionality reduction :  (40000, 2)\n"
     ]
    }
   ],
   "source": [
    "new = processed_df.drop(columns='tweet_id')\n",
    "print('Shape of data before Preprocessing : ',df.shape)\n",
    "print('Shape of data after Preprocessing and dimensionality reduction : ',new.shape)\n",
    "new.to_excel('Emotion-Detection-preprocessing.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information :\n",
    "    1. Reduced from 13 classes to 2 classes as follows:\n",
    "        'happiness' : ['happiness', 'relief', 'love', 'surprise', 'fun', 'enthusiasm','empty']\n",
    "        'sadness' : ['sadness','worry','neutral','hate','anger','boredom']\n",
    "         \n",
    "    2. Data Preprocessing:\n",
    "        > Denoise text\n",
    "        > Remove non-ASCII words\n",
    "        > Converted all letters to lowercase\n",
    "        > Removed Punctuations\n",
    "        > Replaced Numbers to text\n",
    "        > Removed stopwords\n",
    "        > Normalized the text\n",
    "        \n",
    "    3. Dimensionality Reduction:\n",
    "        Dropped \"tweet_id\" column from preprocessed data, as it is unique and doesn't influence the \"sentiment\" column."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
